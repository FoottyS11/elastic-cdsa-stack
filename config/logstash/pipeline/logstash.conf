# =============================================
# LOGSTASH PIPELINE CONFIGURATION
# Pour la CDSA - Analyse de logs sécurité
# =============================================

# =============================================
# INPUT - Sources de données
# =============================================
input {
  # Réception depuis Beats (Filebeat, Winlogbeat, etc.)
  beats {
    port => 5044
    client_inactivity_timeout => 300
  }

  # Réception TCP générique (syslog, applications, etc.)
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp_input"]
  }

  # Réception UDP (syslog)
  udp {
    port => 5000
    codec => json_lines
    tags => ["udp_input"]
  }

  # Syslog standard (RFC 3164 et RFC 5424)
  syslog {
    port => 5514
    tags => ["syslog"]
  }

  # HTTP Input pour recevoir des logs via API
  http {
    port => 8080
    codec => json
    tags => ["http_input"]
  }
}

# =============================================
# FILTER - Traitement et enrichissement
# =============================================
filter {
  # Parsing des logs syslog
  if "syslog" in [tags] {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
    }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }

  # Parsing des logs Apache/Nginx
  if [fileset][name] == "access" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }

  # Parsing des logs Windows (si Winlogbeat)
  if [agent][type] == "winlogbeat" {
    mutate {
      add_tag => ["windows_event"]
    }
  }

  # Parsing des logs SSH
  if [message] =~ /sshd/ {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host} sshd\[%{POSINT:pid}\]: %{GREEDYDATA:ssh_message}" }
    }
    if [ssh_message] =~ /Failed password/ {
      grok {
        match => { "ssh_message" => "Failed password for %{USERNAME:ssh_user} from %{IP:src_ip} port %{NUMBER:src_port}" }
      }
      mutate {
        add_tag => ["ssh_failure", "security_alert"]
      }
    }
    if [ssh_message] =~ /Accepted/ {
      grok {
        match => { "ssh_message" => "Accepted %{WORD:auth_method} for %{USERNAME:ssh_user} from %{IP:src_ip} port %{NUMBER:src_port}" }
      }
      mutate {
        add_tag => ["ssh_success"]
      }
    }
  }

  # Parsing des logs sudo
  if [message] =~ /sudo/ {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host} sudo: %{USERNAME:sudo_user} : %{GREEDYDATA:sudo_command}" }
    }
    mutate {
      add_tag => ["sudo_command", "privilege_escalation"]
    }
  }

  # Enrichissement GeoIP pour toutes les IP source
  if [src_ip] {
    geoip {
      source => "src_ip"
      target => "geoip"
    }
  }

  # Ajout du timestamp de traitement
  ruby {
    code => "event.set('processed_at', Time.now.utc.iso8601)"
  }

  # Suppression des champs inutiles
  mutate {
    remove_field => ["host", "@version"]
  }
}

# =============================================
# OUTPUT - Destinations
# =============================================
output {
  # Envoi vers Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    
    # Index dynamique basé sur le type de log
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    
    # Pour les logs non-beats
    ilm_enabled => true
    ilm_rollover_alias => "logs"
    ilm_pattern => "{now/d}-000001"
  }

  # Debug output (décommenter pour debug)
  # stdout {
  #   codec => rubydebug
  # }
}
