# ğŸ” Elastic Stack CDSA - Platform d'Analyse de Logs

<div align="center">

![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.11.3-00BFB3?style=for-the-badge&logo=elasticsearch)
![Kibana](https://img.shields.io/badge/Kibana-8.11.3-E8478B?style=for-the-badge&logo=kibana)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**Plateforme complÃ¨te d'ingestion, analyse et visualisation de logs pour la cybersÃ©curitÃ©**

[ğŸ“– Documentation](#-documentation) â€¢ [ğŸš€ Installation](#-installation-rapide) â€¢ [ğŸ’¡ Utilisation](#-utilisation) â€¢ [ğŸ¯ Cas d'usage](#-cas-dusage-cdsa)

</div>

---

## ğŸ‘¨â€ğŸ’» Ã€ propos

**Auteur:** CyberLama  
**Profil:** Ã‰tudiant en CybersÃ©curitÃ©  
**Contexte:** PrÃ©paration Ã  la certification **CDSA (Certified DevSecOps Associate)**

### ğŸ“ Objectif du projet

Dans le cadre de mes Ã©tudes en cybersÃ©curitÃ©, j'ai dÃ©veloppÃ© cette stack Elastic dockerisÃ©e pour analyser des logs provenant de diverses sources (CTF, HackTheBox, pentest, forensics). 

Cette plateforme me permet de :
- ğŸ“¥ **Importer** rapidement des fichiers de logs via glisser-dÃ©poser
- ğŸ” **Analyser** des patterns suspects dans des volumes importants de donnÃ©es
- ğŸ“Š **Visualiser** des corrÃ©lations et crÃ©er des dashboards interactifs
- ğŸ¯ **S'entraÃ®ner** sur des scÃ©narios rÃ©els de dÃ©tection d'intrusions

---

## ğŸ—ï¸ Architecture de la stack

```mermaid
graph TB
    A[ğŸ“ Fichiers de Logs<br/>HTB, CTF, Pentest] -->|Upload| B[Kibana UI<br/>Port 5601]
    C[ğŸ“¡ Logs TCP/UDP] -->|Port 5000| D[Logstash<br/>Pipeline]
    
    B --> G[Elasticsearch<br/>Port 9200]
    D --> G
    
    G --> H[Index & Storage]
    H --> I[Dashboards & Analytics]
    
    J[Fleet Server<br/>Port 8220] -->|Gestion| K[Agents Distants]
    
    style A fill:#ff6b6b
    style B fill:#4ecdc4
    style G fill:#00bfb3
    style I fill:#feca57
```

### ğŸ§© Composants

| Service | RÃ´le | Port | Description dÃ©taillÃ©e |
|---------|------|------|----------------------|
| **Elasticsearch** | Moteur de recherche & BDD NoSQL | 9200 | Indexation et stockage distribuÃ© des logs. Recherche full-text ultra-rapide. |
| **Kibana** | Interface de visualisation | 5601 | Dashboard interactif, upload de fichiers, crÃ©ation de visualisations. |
| **Logstash** | Pipeline de traitement | 5000, 5044, 9600 | Parsing, enrichissement et transformation des logs en temps rÃ©el. |
| **Fleet Server** | Gestion centralisÃ©e | 8220 | Orchestration et configuration des agents Elastic distants. |

---

## ğŸ” SÃ©curitÃ© & Authentification

### âš ï¸ Credentials par dÃ©faut

```
Username: elastic
Password: admin
```

> **ğŸš¨ AVERTISSEMENT SÃ‰CURITÃ‰**  
> Ces credentials sont **volontairement faibles** pour faciliter les tests en environnement local.  
> **NE JAMAIS** utiliser ces credentials en production ou exposer la stack sur Internet.

### âœ… Changer les credentials (OBLIGATOIRE en production)

```bash
# 1. Ã‰diter le fichier de configuration
nano .env

# 2. Modifier ces lignes
ELASTIC_PASSWORD=VotreMotDePasseSuperSecurise123!
KIBANA_PASSWORD=VotreMotDePasseSuperSecurise123!

# 3. RecrÃ©er la stack avec les nouveaux credentials
./scripts/reset.sh
./scripts/start.sh
```

**Recommandations :**
- âœ… Minimum 16 caractÃ¨res (majuscules, minuscules, chiffres, symboles)
- âœ… Activer SSL/TLS pour les communications
- âœ… Mettre en place un firewall restrictif
- âœ… Utiliser des certificats signÃ©s en production

---

## ğŸ“‹ PrÃ©requis

- **Docker** 20.10+ ([Installation](https://docs.docker.com/engine/install/))
- **Docker Compose** V2+ (inclus avec Docker Desktop)
- **SystÃ¨me d'exploitation** : Linux, macOS, ou Windows avec WSL2
- **RAM** : 4GB minimum, **8GB recommandÃ©**
- **Ports libres** : 5601, 9200, 5000, 8220

---

## ğŸš€ Installation rapide

### 1ï¸âƒ£ Cloner le repository

```bash
git clone https://github.com/FoottyS11/elastic-cdsa-stack.git
cd elastic-cdsa-stack
```

### 2ï¸âƒ£ Configurer le systÃ¨me (Linux/WSL uniquement)

```bash
# Augmenter la limite memory map (requis pour Elasticsearch)
sudo sysctl -w vm.max_map_count=262144

# Pour rendre permanent (optionnel)
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
```

### 3ï¸âƒ£ Lancer la stack

```bash
./scripts/start.sh
```

**Temps de dÃ©marrage :** ~2 minutes

### 4ï¸âƒ£ AccÃ©der Ã  Kibana

Ouvrir dans le navigateur : **http://localhost:5601**

```
ğŸ‘¤ Username: elastic
ğŸ”‘ Password: admin
```

---

## ğŸ’¡ Utilisation

### ğŸ“¤ Importer vos fichiers de logs

#### MÃ©thode 1 : Upload via Kibana (RecommandÃ©)

1. Ouvrir **Kibana** : http://localhost:5601
2. Menu (â˜°) â†’ **Machine Learning** â†’ **Data Visualizer**
3. Cliquer sur **"Upload file"**
4. **Glisser-dÃ©poser** votre fichier :
   - Formats supportÃ©s : `.log`, `.txt`, `.csv`, `.json`, `.xml`
   - Taille max : 100MB par fichier
5. Kibana dÃ©tecte automatiquement :
   - Le format et la structure
   - Les timestamps
   - Les types de champs
6. Cliquer sur **"Import"** â†’ Vos logs sont indexÃ©s !

#### MÃ©thode 2 : Envoi via Logstash TCP/UDP

```bash
# Envoyer un log via TCP
echo '{"timestamp": "2025-12-23T10:00:00", "level": "ERROR", "message": "Failed login"}' | nc localhost 5000

# Envoyer via UDP
echo "Simple log message" | nc -u localhost 5000
```

#### MÃ©thode 3 : API REST Elasticsearch

```bash
curl -X POST "localhost:9200/mes-logs/_doc" \
  -H 'Content-Type: application/json' \
  -u elastic:admin \
  -d '{
    "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'",
    "message": "Tentative de connexion SSH depuis IP suspecte",
    "level": "warning",
    "source_ip": "192.168.1.100",
    "service": "ssh"
  }'
```

### ğŸ“Š CrÃ©er des visualisations

1. **Kibana** â†’ **Analytics** â†’ **Dashboard**
2. Cliquer sur **"Create dashboard"**
3. Ajouter des visualisations :
   - **Line chart** : Ã‰volution temporelle
   - **Pie chart** : RÃ©partition par catÃ©gorie
   - **Data table** : Tableaux de logs
   - **Heat map** : CorrÃ©lations
   - **Geo map** : Localisation gÃ©ographique des IPs
4. Filtrer avec **KQL** (Kibana Query Language)

### ğŸ” Exemples de requÃªtes KQL

```
# Rechercher des erreurs
level: "error" OR level: "critical"

# Logs SSH des 24 derniÃ¨res heures
service: "ssh" AND @timestamp > now-24h

# Ã‰checs d'authentification
message: *"failed"* OR message: *"denied"*

# RequÃªtes depuis une IP spÃ©cifique
source.ip: "192.168.1.100"

# Combinaison complexe
(level: "error" OR level: "warning") AND service: "apache" AND @timestamp > now-1h
```

---

## ğŸ› ï¸ Gestion de la stack

### â–¶ï¸ DÃ©marrer la stack

```bash
./scripts/start.sh
```

**Ce script effectue :**
1. âœ… Configuration systÃ¨me (`vm.max_map_count`)
2. âœ… DÃ©marrage de tous les conteneurs Docker
3. âœ… VÃ©rification de l'Ã©tat de santÃ© des services
4. âœ… Affichage des URLs d'accÃ¨s

### â¸ï¸ ArrÃªter la stack

```bash
./scripts/stop.sh
```

**Ce script :**
- ğŸ›‘ ArrÃªte tous les conteneurs proprement
- ğŸ’¾ **Conserve toutes vos donnÃ©es** (volumes Docker persistants)
- âš¡ Les logs et indices restent intacts

**Quand utiliser `stop.sh` ?**
- LibÃ©rer des ressources systÃ¨me temporairement
- RedÃ©marrer votre machine
- Fin de session de travail

**Important :** Relancer avec `./scripts/start.sh` restaure tout votre environnement.

### ğŸ”„ RÃ©initialiser complÃ¨tement

```bash
./scripts/reset.sh
```

**âš ï¸ ATTENTION : Ce script :**
- ğŸ—‘ï¸ **SUPPRIME DÃ‰FINITIVEMENT** tous les conteneurs
- ğŸ—‘ï¸ **EFFACE TOUS LES VOLUMES** (logs, indices, configurations)
- ğŸ—‘ï¸ Supprime le rÃ©seau Docker
- ğŸ§¹ Nettoie complÃ¨tement l'environnement

**Quand utiliser `reset.sh` ?**
- âœ… Repartir de zÃ©ro avec une stack propre
- âœ… Changer les credentials (modifications dans `.env`)
- âœ… Corriger une configuration cassÃ©e
- âœ… LibÃ©rer de l'espace disque

**AprÃ¨s un reset :**
```bash
./scripts/start.sh  # RecrÃ©er la stack from scratch
```

### ğŸ“Š VÃ©rifier l'Ã©tat des services

```bash
docker compose ps
```

### ğŸ“œ Consulter les logs

```bash
# Tous les services
docker compose logs -f

# Service spÃ©cifique
docker compose logs -f elasticsearch
docker compose logs -f kibana
```

---

## ğŸ¯ Cas d'usage CDSA

### ğŸ“ ScÃ©narios d'apprentissage

#### 1. **Analyse de logs HTB/CTF**
- Import de logs d'attaques web (SQLi, XSS, LFI)
- Identification de payloads malveillants
- Timeline de l'intrusion

#### 2. **Forensics & Incident Response**
- Centralisation de logs multi-sources
- CorrÃ©lation d'Ã©vÃ©nements suspects
- Recherche de IoC (Indicators of Compromise)

#### 3. **DÃ©tection d'intrusions**
- Pattern matching sur tentatives de brute-force
- DÃ©tection d'anomalies (connexions inhabituelles)
- Alertes sur Ã©vÃ©nements critiques

#### 4. **Monitoring applicatif**
- Logs d'applications web (Apache, Nginx)
- TraÃ§abilitÃ© des erreurs 500/404
- Performance monitoring

#### 5. **Pentest reporting**
- AgrÃ©gation des rÃ©sultats de scans (Nmap, Nessus)
- Visualisation des vulnÃ©rabilitÃ©s
- GÃ©nÃ©ration de rapports

---

## ğŸ“ Structure du projet

```
elastic-cdsa-stack/
â”œâ”€â”€ ğŸ“„ docker-compose.yml        # Orchestration des 4 services
â”œâ”€â”€ ğŸ“„ .env                      # Configuration (passwords, ports, resources)
â”œâ”€â”€ ğŸ“„ README.md                 # Cette documentation
â”‚
â”œâ”€â”€ ğŸ“‚ config/
â”‚   â”œâ”€â”€ ğŸ“‚ logstash/
â”‚   â”‚   â”œâ”€â”€ logstash.yml         # Config Logstash
â”‚   â”‚   â””â”€â”€ pipeline/
â”‚   â”‚       â””â”€â”€ logstash.conf    # Pipeline de parsing
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ 
â”‚
â””â”€â”€ ğŸ“‚ scripts/
    â”œâ”€â”€ ğŸš€ start.sh              # DÃ©marrage de la stack
    â”œâ”€â”€ â¸ï¸  stop.sh               # ArrÃªt (conserve les donnÃ©es)
    â””â”€â”€ ğŸ”„ reset.sh              # RÃ©initialisation complÃ¨te
```

---

## ğŸ”§ Configuration avancÃ©e

### Ajuster les ressources mÃ©moire

Ã‰diter `.env` :

```bash
# Pour machines avec 8GB+ RAM
ES_JAVA_OPTS=-Xms2g -Xmx2g
LS_JAVA_OPTS=-Xms1g -Xmx1g

# Pour machines avec 4GB RAM (minimal)
ES_JAVA_OPTS=-Xms1g -Xmx1g
LS_JAVA_OPTS=-Xms512m -Xmx512m
```

### Personnaliser les ports

```bash
# Dans .env
ES_PORT=9200
KIBANA_PORT=5601
LOGSTASH_TCP_PORT=5000
FLEET_PORT=8220
```

---

## ğŸ› DÃ©pannage

### Elasticsearch ne dÃ©marre pas

**Erreur :** `max virtual memory areas vm.max_map_count [65530] is too low`

**Solution :**
```bash
sudo sysctl -w vm.max_map_count=262144
```

### Kibana affiche "Kibana server is not ready yet"

**Causes possibles :**
- Elasticsearch encore en cours de dÃ©marrage (attendre 2-3 min)
- ProblÃ¨me de connexion rÃ©seau interne Docker

**Solutions :**
```bash
# VÃ©rifier qu'Elasticsearch rÃ©pond
curl -u elastic:admin http://localhost:9200

# RedÃ©marrer Kibana si nÃ©cessaire
docker compose restart kibana
```

### Pas assez de mÃ©moire

**SymptÃ´mes :** Conteneurs qui crashent, lenteurs

**Solutions :**
1. RÃ©duire `ES_JAVA_OPTS` dans `.env`
2. Augmenter la RAM allouÃ©e Ã  Docker Desktop
3. Fermer d'autres applications

### Reset en cas de problÃ¨me

```bash
./scripts/reset.sh
./scripts/start.sh
```

---

## ğŸ“š Ressources & Documentation

### Documentation officielle Elastic

- ğŸ“– [Elasticsearch Reference](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- ğŸ“– [Kibana Guide](https://www.elastic.co/guide/en/kibana/current/index.html)
- ğŸ“– [Logstash Documentation](https://www.elastic.co/guide/en/logstash/current/index.html)
- ğŸ“– [Upload Files to Kibana](https://www.elastic.co/guide/en/kibana/current/connect-to-elasticsearch.html#upload-data-kibana)

### Tutoriels & Apprentissage

- ğŸ“ [Kibana Query Language (KQL)](https://www.elastic.co/guide/en/kibana/current/kuery-query.html)
- ğŸ“ [Creating Visualizations](https://www.elastic.co/guide/en/kibana/current/create-a-dashboard-of-panels-with-web-server-data.html)
- ğŸ“ [Elastic SIEM](https://www.elastic.co/guide/en/security/current/index.html)

### Certifications

- ğŸ¯ [CDSA - Certified DevSecOps Associate](https://www.practical-devsecops.com/certified-devsecops-associate/)
- ğŸ¯ [Elastic Certified Engineer](https://www.elastic.co/training/certification)

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! 

**Pour contribuer :**
1. Fork ce repository
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit vos changements (`git commit -m 'Ajout de fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

**IdÃ©es de contributions :**
- ğŸ“ Ajout de pipelines Logstash prÃ©-configurÃ©s
- ğŸ“Š Templates de dashboards pour diffÃ©rents cas d'usage
- ğŸ› Corrections de bugs
- ğŸ“– AmÃ©lioration de la documentation

---

## ï¿½ï¿½ Licence

**MIT License** - Libre d'utilisation pour l'apprentissage et la formation.

```
Copyright (c) 2025 CyberLama

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction.
```

---

## âš¡ Statut de la stack

| Service | Statut | Description |
|---------|--------|-------------|
| Elasticsearch | âœ… Operational | Indexation & recherche full-text |
| Kibana | âœ… Accessible | Interface web avec upload de fichiers |
| Logstash | âœ… Pipeline actif | Parsing TCP/UDP/Beats |
| Fleet Server | âœ… OpÃ©rationnel | Gestion centralisÃ©e agents |

---

## ğŸ“¬ Contact

**CyberLama**  
ğŸ“ Ã‰tudiant en CybersÃ©curitÃ©  
ğŸ¯ CDSA in progress

ğŸ“§ Questions ? Ouvrez une [issue](https://github.com/FoottyS11/elastic-cdsa-stack/issues)

---

<div align="center">

**â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une Ã©toile ! â­**

Made with â¤ï¸ by CyberLama pour la communautÃ© cybersÃ©curitÃ©

</div>
