# ğŸ” Stack Elastic CDSA - Docker Compose

Stack Elastic complÃ¨te et prÃªte Ã  l'emploi pour la **Certification DevSecOps Associate (CDSA)**. Cette stack inclut Elasticsearch, Kibana, Logstash, Metricbeat et Fleet Server pour **l'import, l'analyse et la visualisation de vos fichiers de logs** (HTB, CTF, etc.).

## âš ï¸ SÃ‰CURITÃ‰ - Ã€ LIRE EN PREMIER

**Credentials par dÃ©faut : `admin / admin`**

ğŸš¨ **IMPORTANT** : Cette stack utilise des credentials **TRÃˆS FAIBLES** par dÃ©faut (`admin/admin`) pour faciliter les tests.

**AVANT toute utilisation sÃ©rieuse :**
1. Modifier `ELASTIC_PASSWORD` et `KIBANA_PASSWORD` dans le fichier `.env`
2. Relancer la stack : `./scripts/reset.sh && ./scripts/start.sh`
3. Ne **JAMAIS** exposer cette stack sur Internet avec ces credentials

## ğŸ“‹ PrÃ©requis

- Docker 20.10+
- Docker Compose V2+
- 4GB RAM minimum (8GB recommandÃ©)
- Ports disponibles: 5601, 9200, 5044, 8220

## ğŸš€ DÃ©marrage rapide

\`\`\`bash
# Cloner le repo
git clone https://github.com/VOTRE_USERNAME/elastic-cdsa-stack.git
cd elastic-cdsa-stack

# Lancer la stack
sudo sysctl -w vm.max_map_count=262144
./scripts/start.sh

# Attendre 1-2 minutes que tous les services dÃ©marrent
\`\`\`

## ğŸŒ AccÃ¨s aux services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Kibana** | http://localhost:5601 | **admin / admin** âš ï¸ |
| **Elasticsearch** | http://localhost:9200 | **admin / admin** âš ï¸ |
| **Logstash** | http://localhost:9600 | - |
| **Fleet Server** | http://localhost:8220 | - |

## ğŸ› ï¸ Commandes utiles

\`\`\`bash
# DÃ©marrer la stack
./scripts/start.sh

# ArrÃªter la stack
./scripts/stop.sh

# RÃ©initialiser complÃ¨tement (âš ï¸ supprime toutes les donnÃ©es)
./scripts/reset.sh

# Voir les logs
sudo docker compose logs -f [service_name]

# VÃ©rifier le statut
sudo docker compose ps
\`\`\`

## ğŸ“¦ Services inclus

### 1. **Elasticsearch** (Port 9200)
- Moteur de recherche et base de donnÃ©es NoSQL
- Stocke tous les logs et mÃ©triques
- Cluster en mode single-node

### 2. **Kibana** (Port 5601)
- Interface web pour visualiser les donnÃ©es
- Dashboards prÃ©-configurÃ©s
- Gestion de Fleet Server

### 3. **Logstash** (Ports 5044, 5000, 9600)
- Pipeline de traitement des donnÃ©es
- ReÃ§oit les logs via TCP/UDP (port 5000)
- API de monitoring (port 9600)

### 4. **Metricbeat**
- Collecte les mÃ©triques systÃ¨me (CPU, RAM, disque)
- Surveillance Docker
- MÃ©triques rÃ©seau

### 5. **Fleet Server** (Port 8220)
- Gestion centralisÃ©e des agents Elastic
- DÃ©ploiement de politiques
- Surveillance des agents

## ğŸ“Š Import de logs

### ğŸ¯ Via Kibana UI - Upload de fichiers (RECOMMANDÃ‰ pour HTB/CTF)
1. Ouvrir Kibana: http://localhost:5601
2. **Menu** (â˜°) â†’ **Machine Learning** â†’ **Data Visualizer**
3. Cliquer sur **Upload file**
4. **Glisser-dÃ©poser** ton fichier de logs (`.log`, `.txt`, `.csv`, `.json`)
5. Kibana dÃ©tecte automatiquement le format et crÃ©e l'index
6. Cliquer sur **Import** pour analyser tes logs

### Via Kibana - Index Management
1. **Menu** â†’ **Management** â†’ **Stack Management**
2. **Data** â†’ **Index Management**
3. **Create data view** pour visualiser tes donnÃ©es

### Via Logstash TCP/UDP
\`\`\`bash
# Envoyer des logs via TCP
echo "Mon log de test" | nc localhost 5000

# Envoyer des logs via UDP
echo "Mon log UDP" | nc -u localhost 5000
\`\`\`

### Via Filebeat
Filebeat collecte automatiquement:
- \`/var/log/syslog\`
- \`/var/log/auth.log\`
- Logs des conteneurs Docker
\`\`\`

### Via API Elasticsearch
\`\`\`bash
curl -X POST "localhost:9200/mes-logs/_doc" \\
  -H 'Content-Type: application/json' \\
  -u elastic:admin \
  -d '{
    "timestamp": "'\$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'",
    "message": "Mon message de log",
    "level": "info",
    "source": "mon-app"
  }'
\`\`\`

## ï¿½ï¿½ SÃ©curitÃ©

**âš ï¸ DANGER - Credentials faibles par dÃ©faut !**

Cette stack utilise `admin/admin` par dÃ©faut. **C'EST EXTRÃŠMEMENT DANGEREUX** si exposÃ© !

### âœ… Changer les mots de passe (OBLIGATOIRE pour usage rÃ©el)

```bash
# 1. Ã‰diter le fichier .env
nano .env

# 2. Modifier ces lignes :
ELASTIC_PASSWORD=VotreMotDePasseForT123!
KIBANA_PASSWORD=VotreMotDePasseForT123!

# 3. RÃ©initialiser la stack
./scripts/reset.sh
./scripts/start.sh
```

### Pour la production :
- âœ… **Changer TOUS les mots de passe** (minimum 16 caractÃ¨res)
- âœ… Activer SSL/TLS
- âœ… Configurer un firewall strict
- âœ… Utiliser des certificats valides
- âœ… Ne JAMAIS exposer sur Internet avec `admin/admin`

## ğŸ“ Structure du projet

\`\`\`
.
â”œâ”€â”€ docker-compose.yml          # Configuration des services
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ logstash/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ logstash.yml   # Config Logstash
â”‚   â”‚   â””â”€â”€ pipeline/
â”‚   â”‚       â””â”€â”€ logstash.conf  # Pipeline de traitement
â”‚   â””â”€â”€ metricbeat/
â”‚       â””â”€â”€ metricbeat.yml     # Config collecte de mÃ©triques
â””â”€â”€ scripts/
    â”œâ”€â”€ start.sh               # DÃ©marrage de la stack
    â”œâ”€â”€ stop.sh                # ArrÃªt de la stack
    â””â”€â”€ reset.sh               # RÃ©initialisation complÃ¨te
\`\`\`

## ğŸ¯ Cas d'usage CDSA

Cette stack permet de:
- âœ… **Uploader et analyser vos fichiers de logs** (HTB, CTF, pentest)
- âœ… Centraliser les logs de plusieurs sources
- âœ… Analyser les Ã©vÃ©nements de sÃ©curitÃ©
- âœ… Surveiller les mÃ©triques systÃ¨me
- âœ… CrÃ©er des dashboards de monitoring
- âœ… DÃ©tecter des anomalies
- âœ… CorrÃ©ler des Ã©vÃ©nements
- âœ… Pratiquer l'analyse forensique

## ğŸ› DÃ©pannage

### Les conteneurs ne dÃ©marrent pas
\`\`\`bash
# VÃ©rifier vm.max_map_count
sysctl vm.max_map_count  # Doit Ãªtre >= 262144
sudo sysctl -w vm.max_map_count=262144

# VÃ©rifier les logs
sudo docker compose logs elasticsearch
\`\`\`

### Pas de donnÃ©es dans Kibana
\`\`\`bash
# VÃ©rifier que les services fonctionnent
sudo docker compose ps

# VÃ©rifier les indices dans Elasticsearch
curl -u elastic:admin http://localhost:9200/_cat/indices?v
\`\`\`

### Comment uploader mes fichiers de logs ?
1. Ouvrir Kibana: http://localhost:5601
2. Menu â†’ Machine Learning â†’ Data Visualizer â†’ **Upload file**
3. Glisser-dÃ©poser ton fichier \`.log\`, \`.txt\`, \`.csv\` ou \`.json\`
4. Suivre l'assistant d'import

### Erreur de mÃ©moire
- Augmenter la RAM allouÃ©e Ã  Docker
- RÃ©duire \`ES_JAVA_OPTS\` dans [.env](.env)
- RÃ©duire \`LS_JAVA_OPTS\` dans [.env](.env)

## ğŸ“š Documentation

- [Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Kibana](https://www.elastic.co/guide/en/kibana/current/index.html)
- [Logstash](https://www.elastic.co/guide/en/logstash/current/index.html)
- [Upload files to Kibana](https://www.elastic.co/guide/en/kibana/current/connect-to-elasticsearch.html#upload-data-kibana)

## ğŸ¤ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã  ouvrir une issue ou une PR.

## ï¿½ï¿½ Licence

MIT License - Libre d'utilisation pour l'apprentissage et la formation CDSA.

## âš¡ Stack testÃ©e et fonctionnelle

- âœ… Elasticsearch: Operational
- âœ… Kibana: Accessible sur port 5601 avec **Upload file**
- âœ… Logstash: Pipeline actif

- âœ… Metricbeat: Collecte mÃ©triques
- âœ… Fleet Server: Gestion d'agents

---

**Bon apprentissage pour la CDSA! ğŸ“**
